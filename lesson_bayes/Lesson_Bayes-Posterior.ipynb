{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df1e245d",
   "metadata": {},
   "source": [
    "# Lesson Bayes: Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f8c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc20d00",
   "metadata": {},
   "source": [
    "# Posterior Distribution\n",
    "The distribution that enables *inference*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71965b25",
   "metadata": {},
   "source": [
    "# Given data what have we learned\n",
    "We've covered a many topics so let's restate what we're here. \n",
    "\n",
    "As statisticians, if we have some observed *samples* of the world, what is our belief?\n",
    "\n",
    "As *Bayesian* statisticians, if we have some observed *samples* of the world, a model and a prior belief, what is our updated belief after incorporating our observations? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98093f31",
   "metadata": {},
   "source": [
    "# Your First Bayesian Model\n",
    "Go through AB test with conjugancy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22bbd04",
   "metadata": {},
   "source": [
    "# This is our updated belief"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a289e56",
   "metadata": {},
   "source": [
    "# What do we need PPLs for?\n",
    "In simple cases obtaining the posterior is straightforward. Once you get "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec160a1",
   "metadata": {},
   "source": [
    "# There are many methods to infer hte posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373d7224",
   "metadata": {},
   "source": [
    "# We'll be using MCMC\n",
    "This is the \"magic inference\" button. MCMC is a method that has gained a lot of momentum in the last decade because it \n",
    "* Works well on many bayesian models\n",
    "* Is efficient and returns results relatively quickly\n",
    "* Comes with a good set of diagnostics\n",
    "\n",
    "A big job of modern PPLs is to serve as an interface to methods such as MCMC. \n",
    "MCMC is not not without its downsides, but its very good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630aa95c",
   "metadata": {},
   "source": [
    "# Section Recap\n",
    "* Posterior distributions \n",
    "    * allow us to perform *inference* the goal of statistics\n",
    "    * incorporate the data, the model, and our priors\n",
    "* Postterior estimation is not always \"easy or straightforward\"\n",
    "    * PPLs use a flexible technique called MCMC to estimate posteriors with samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
